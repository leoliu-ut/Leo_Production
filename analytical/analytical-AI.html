<!doctype html>
<html lang="en">
<head>

    <title>Analytical | Leo Portfolio</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="description" content=""/>

    <!-- this styles only adds some repairs on idevices  -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- CSS -->

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="css/style.css">
    <script src="https://kit.fontawesome.com/6696d2b997.js" crossorigin="anonymous"></script>

</head>


<body class="home">


<!-- / Site Header -->
<div class="site-header">

    <!-- / Site Logo -->
    <div class="site-logo">

        <a href="https://leoliu-ut.github.io/Leo_Production/index.html"> <img src="pics/logo.png"
                                                                              style="width: 38%"/></a>

    </div>
    <!-- \ Site Logo -->


    <!-- / Site Menu -->
    <div class="site-menu">
        <div class="icon"></div>
        <div class="menu">
            <ul>

                <li><a href="https://leoliu-ut.github.io/Leo_Production/portfolio/portfolioindex.html">Creative Works</a>
                </li><li><a href="https://leoliu-ut.github.io/Leo_Production/analytical/analyticalindex.html">Analytical
                    Works</a></li>
                <li><a href="https://leoliu-ut.github.io/Leo_Production/contact.html">Contact</a></li>

            </ul>
        </div>
    </div>
    <!-- \ Site Menu -->


    <!-- / Site Description -->
    <h1>

        A creative, passionate
        <br>and motivated film enthusiast, <br>combined with a data aficionado.
        <br><br>
        I’m currently <br> mixing up my passion <br>for creative production <br>with my love of data analytics,
        <br> and applying it to marketing.

    </h1>

    <!-- \ Site Description -->


    <!-- / Site Footer -->
    <div class="site-footer">

        <div class="site-social">
            <ul>
                <li><a href="https://vimeo.com/leozliu"> <i class="fab fa-vimeo" style="color: #86C9EF"></i></a></li>
                <li><a href="https://www.linkedin.com/in/leozliu"> <i class="fab fa-linkedin"
                                                                      STYLE="color: #1da1f2"></i></a></li>
                <li><a href="https://www.instagram.com/leozliu/"><i class="fab fa-instagram" style=" color: transparent;
    background: radial-gradient(circle at 30% 107%, #fdf497 0%, #fdf497 5%, #fd5949 45%, #d6249f 60%, #285AEB 90%);
    background: -webkit-radial-gradient(circle at 30% 107%, #fdf497 0%, #fdf497 5%, #fd5949 45%, #d6249f 60%, #285AEB 90%);
    /*background-clip: text;*/
    -webkit-background-clip: text;"></i></a></li>
            </ul>
            <br>
        </div>
        <p>© 2020 Leo Z. Liu <br>
            All rights reserved</p>

    </div>
    <!-- \ Site Footer -->

</div>
<!-- \ Site Header -->


<!-- \ Site Main -->
<div class="site-main">
    <ul class="row grid cs-style-2">

        <div class="inner clearfix">
            <h3>AI Facial Recognition Model</h3>
        </div>
        <ul class="row grid cs-style-2">

                <img src="pics/how_ru_feeling/1.png" alt="how are you feeling poster">
        </ul>
        <div class="inner clearfix">
            <p style="font-size: 16px">
                <u><b><em>Problem</em></b></u>: Most of us take identifying emotions and emotional intelligence for
                granted. It feels natural and it is considered a basic human social skill. However, not everyone can do
                this easily! 1 in 10 people fall on the spectrum and have difficulty identifying and describing
                emotions. We built a model
                based on thousands of photos containing people’s faces. It can recognize
                human emotions from the pictures. This could facilitate people communication better due to the fact that
                55% of communication is based on body language including facial features.
            </p>
        </div>
        <ul class="row grid cs-style-2">

                <img src="pics/how_ru_feeling/2.png" alt="how are you feeling data">

                <img src="pics/how_ru_feeling/3.png" alt="how are you feeling waht we did">

        </ul>

        <div class="inner clearfix">
            <p style="font-size: 16px">
                <u><b><em>Datasets</em></b></u>
                : <br><u>The Japanese Female Facial Expression (JAFFE) Database. </u><br>
                <small>This database contains a total of 213 gray-scaled images of 10 different Japanese woman.
                    Each woman has a picture of a facial expression for a total of 7 different facial expressions:
                    happy,
                    neutral, sad, surprise, anger, disgust, and fear. 60 different people rated each photo on a scale of
                    1-5
                    (1 = low notability 5 = high notability) for each of the 6 emotions. The average rates per
                    emotion
                    per photo are given in the experiment’s dataset along with the images.
                    (http://www.kasrl.org/jaffe.html)
                </small>
                <br>
                <br>
                <u>Specs on Faces (SoF) Dataset.</u><br>
                <small>A collection of 42,592 (2,662×16) images for 112 persons (66 males and 46 females) who wear
                    glasses under different illumination conditions. The dataset is FREE for reasonable academic fair
                    use. (https://sites.google.com/view/sof-dataset)
                </small>

            </p>
        </div>
        <ul class="row grid cs-style-2">

                <img src="pics/how_ru_feeling/6.png" alt="how are you feeling dataset">

        </ul>

        <div class="inner clearfix">
            <p style="font-size: 16px">
                <u><b><em>Approcah</em></b></u>:
                <br>
                <i>Challenges</i>:<br>
                Inconsistency.
                <small> In the JAFFE Dataset, the image order was inconsistent with the order in the directory
                    which caused problems with matching the right emotion label with the right image.<br></small>

                Different ratings.
                <small>In the JAFFE Dataset, all of the images were named slightly different in the
                    ratings text file than in the directory.<br></small>
                Conversion.
                <small>For the SoF Dataset, the emotion labels were in a Matlab file so we had to download
                    Matlab and figure out how to extract information from a Structure Array and save it into a CSV file
                    Data cleaning.
                    <br><br></small>
                <i> Transforming</i>:<br>
                <small>Darwin does not support convolutional neural networks. Our first approach involved us obtaining
                    grayscale color values for every pixel of each image
                    This method FAILED. <br>
                    Then, we researched and found a facial recognition package that we could install.
                    The package was able to take in the images and export 72 points per image of the face’s main
                    landmarks.
                    Which include the chin, eyebrows, nose, eyes, and lips.
                </small>
                <br>
                <strong>2556 </strong> comparisons <strong> 10244 </strong>features generated!


            </p>
        </div>
        <ul class="row grid cs-style-2">

                <img src="pics/how_ru_feeling/5.png" alt="how are you feeling approach and setup">

        </ul>

        <div class="inner clearfix">
            <p style="font-size: 16px">
                <u><b><em>Feature generation</em></b></u>: We attempted several different versions of feature generation
                and learned that including all feature
                types does not make the model better
                Here, you can see that for our original model, we included all Feature Types. Euclidean distance, x
                distance, y distance, and the angle.
            </p>
        </div>
        <ul class="row grid cs-style-2">

                <img src="pics/how_ru_feeling/7.png" alt="how are you feeling feature generation">

        </ul>
        <div class="inner clearfix">
            <p style="font-size: 16px">
                <u><b><em>What we learned</em></b></u>:
                XGBoost classifier model is the best.
                Most important features always came from the top and bottom lip with the Y-distance as the most
                important feature type. Meaning the model heavily relies on how far apart the top lip is from the bottom
                lip.

            </p>
        </div>
        <ul class="row grid cs-style-2">

                <img src="pics/how_ru_feeling/8.png" alt="how are you feeling learning">

        </ul>
        <div class="inner clearfix">
            <p style="font-size: 16px">
                <u><b><em>Demo</em></b></u>: Our model successfully recognizes facial expressions of teammates.
            </p>
        </div>
        <ul class="row grid cs-style-2">

                <img src="pics/how_ru_feeling/9.png" alt="how are you feeling demo">

        </ul>

        <div class="inner clearfix">
            <p style="font-size: 16px">
                <u><b><em>Next steps</em></b></u>: <br>Expand our dataset and explore more. <br>
                Analyze the percentages of each emotion instead of focusing on the most significant one. Most likely,
                our facial expression can show a combination of several emotions, such as happy and surprised, fearful
                but angry. So we believe it could be better to analyze the percentage of each emotion, to get a more
                accurate result.<br>
                Extend our analysis to include voice and body languages. Many people try to control their emotions. If
                we can combine the facial expression, voice, and body language together, we can analyze emotional status
                more accurately. </p>
        </div>
        <ul class="row grid cs-style-2">

                <img src="pics/how_ru_feeling/11.png" alt="how are you feeling next steps">

        </ul>

        <ul class="row grid cs-style-2">

                <img src="pics/how_ru_feeling/12.png" alt="how are you feeling conclusion">

        </ul>
        <br>
        <br>
        <!--GO BACK-->
        <div class="col-md-6" style="float: right">
            <a href="analyticalindex.html"> <input type="submit" class="form-control" value="Go Back"></a>
            &nbsp;&nbsp;&nbsp;&nbsp;<br>
        </div>
    </ul>
</div>
<!-- / Site Main -->


<!-- / JS Files  -->

<!-- jQuery -->
<script src="js/jQuery/jquery-2.1.1.js"></script>

<!-- Theme Functions -->
<script src="js/functions.js"></script>


</body>
</html>

