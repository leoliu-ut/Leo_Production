<!doctype html>
<html lang="en">
<head>

    <title> AI Facial Recognition Model | Leo Z Liu Production</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="description" content=""/>

    <!-- this styles only adds some repairs on idevices  -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- CSS -->

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="css/style.css">
    <script src="https://kit.fontawesome.com/6696d2b997.js" crossorigin="anonymous"></script>

</head>


<body class="home">


<!-- / Site Header -->
<div class="site-header">

    <!-- / Site Logo -->
    <div class="site-logo">

        <a href="https://leoliu-ut.github.io/Leo_Production/index.html"> <img src="pics/logo.png"
                                                                              style="width: 38%"/></a>
        <br>
        <h1>Leo Z. Liu</h1>

    </div>
    <!-- \ Site Logo -->


    <!-- / Site Menu -->
    <div class="site-menu">
        <div class="icon"></div>
        <div class="menu">
            <ul>

                <li><a href="https://leoliu-ut.github.io/Leo_Production/portfolio/portfolioindex.html">Creative
                    Works</a>
                </li>
                <li><a href="https://leoliu-ut.github.io/Leo_Production/analytical/analyticalindex.html">Analytical
                    Works</a></li>
                <li><a href="https://leoliu-ut.github.io/Leo_Production/contact.html">Contact</a></li>

            </ul>
        </div>
    </div>
    <!-- \ Site Menu -->


    <!-- / Site Description -->
    <h1>

        A creative, passionate
        <br>and motivated film enthusiast, <br>combined with a data aficionado.
        <br><br>
        I’m currently <br> mixing up my passion <br>for creative production <br>with my love of data analytics,
        <br> and applying it to marketing.

    </h1>

    <!-- \ Site Description -->


    <!-- / Site Footer -->
    <div class="site-footer">

        <div class="site-social">
            <ul>
                <li><a href="https://vimeo.com/leozliu"> <i class="fab fa-vimeo" style="color: #86C9EF"></i></a></li>
                <li><a href="https://www.linkedin.com/in/leozliu"> <i class="fab fa-linkedin"
                                                                      STYLE="color: #1da1f2"></i></a></li>
                <li><a href="https://www.instagram.com/leozliu/"><i class="fab fa-instagram" style=" color: transparent;
    background: radial-gradient(circle at 30% 107%, #fdf497 0%, #fdf497 5%, #fd5949 45%, #d6249f 60%, #285AEB 90%);
    background: -webkit-radial-gradient(circle at 30% 107%, #fdf497 0%, #fdf497 5%, #fd5949 45%, #d6249f 60%, #285AEB 90%);
    /*background-clip: text;*/
    -webkit-background-clip: text;"></i></a></li>
            </ul>
            <br>
        </div>
        <p>© 2020 Leo Z. Liu <br>
            All rights reserved</p>

    </div>
    <!-- \ Site Footer -->

</div>
<!-- \ Site Header -->


<!-- \ Site Main -->
<div class="site-main">
    <ul class="row grid cs-style-2">

        <div class="inner clearfix">
            <h3>AI Facial Recognition Model</h3>
        </div>
        <ul class="row grid cs-style-2">

            <img src="pics/how_ru_feeling/1.png" alt="how are you feeling poster">
        </ul>
        <div class="inner clearfix">
            <p style="font-size: 16px">
                <u><b><em>Problem</em></b></u>:
                <br>Most of us take identifying emotions and emotional intelligence for granted. It feels natural and it
                is considered a basic human social skill. However, not everyone can do this easily! 1 in 10 people fall
                on the spectrum and have difficulty identifying and describing emotions. We built a model based on
                thousands of photos containing people’s faces. It can recognize human emotions from pictures. This could
                facilitate people's communication better due to the fact that 55% of communication is based on body
                language including facial features.
            </p>
        </div>
        <ul class="row grid cs-style-2">

            <img src="pics/how_ru_feeling/2.png" alt="how are you feeling data">

            <img src="pics/how_ru_feeling/3.png" alt="how are you feeling what we did">

        </ul>

        <div class="inner clearfix">
            <p style="font-size: 16px">
                <u><b><em>Datasets</em></b></u>
                : <br><u>The Japanese Female Facial Expression (JAFFE) Database. </u><br>
                <small>This database contains a total of 213 gray-scaled images of 10 different Japanese women.
                    Each woman has a picture of a facial expression for a total of 7 different facial expressions:
                    happy,
                    neutral, sad, surprise, anger, disgust, and fear. 60 different people rated each photo on a scale of
                    1-5
                    (1 = low notability 5 = high notability) for each of the 6 emotions. The average rates per
                    emotion
                    per photo are given in the experiment’s dataset along with the images.
                    (http://www.kasrl.org/jaffe.html)
                </small>
                <br>
                <br>
                <u>Specs on Faces (SoF) Dataset.</u><br>
                <small>A collection of 42,592 (2,662×16) images for 112 persons (66 males and 46 females) who wear
                    glasses under different illumination conditions. The dataset is FREE for reasonable academic fair
                    use. (https://sites.google.com/view/sof-dataset)
                </small>

            </p>
        </div>
        <ul class="row grid cs-style-2">

            <img src="pics/how_ru_feeling/6.png" alt="how are you feeling dataset">

        </ul>

        <div class="inner clearfix">
            <p style="font-size: 16px">
                <u><b><em>Approach</em></b></u>:
                <br>
                <i>Challenges</i>:
            </p>
            <ul style="font-size: 16px;">
                <li style="list-style: inside circle none;  text-align: left; margin: 0 0 0 2%;">Inconsistency
                    <br> In the JAFFE Dataset, the image order was inconsistent with the order in the directory
                    which caused problems with matching the correct emotion label with the image.
                </li>
                <br>
                <li style="list-style: inside circle none;  text-align: left; margin: 0 0 0 2%;">Different ratings
                    <br>In the JAFFE Dataset, all images were named slightly differently in the
                    rating text file than in the directory.
                </li>
                <br>
                <li style="list-style: inside circle none;  text-align: left; margin: 0 0 0 2%;">Conversion
                    <br>In the SoF Dataset, the emotion labels were in a Matlab file. So we had to download
                    Matlab and figure out how to extract information from a Structure Array and save it into a CSV file
                    Data cleaning.
                </li>
                <br>
            </ul>
            <p style="font-size: 16px">
                <br>
                <i>Transformation</i>:
            </p>
            <ul style="font-size: 16px;">
                <li style="list-style: inside none none;  text-align: left; margin: 0 0 0 2%;">
                    <br>Our first attempt was to apply convolutional
                    neural networks directly. However, Darwin (the required API for this project), developed by <a
                        herf="https://www.sparkcognition.com/">SparkCognition</a>, does not support it. So we needed
                    to figure out a way to make these images readable to Darwin. <br>
                    <br>Our first approach involved us obtaining grayscale color values for every pixel of each image.
                    This method FAILED. <br><br>
                    Then, after researching deeply, I found a facial recognition package that we could install. This
                    package benefited the team a lot. It was able to take in the images and export 72 points per image
                    on the face’s main
                    landmarks, which include the chin, eyebrows, nose, eyes, and lips.
                    <br><br>In total, <strong>2556 </strong> comparisons <strong> 10244 </strong>features generated!
                </li>
            </ul>


            </p>
        </div>
        <ul class="row grid cs-style-2">

            <img src="pics/how_ru_feeling/5.png" alt="how are you feeling approach and setup">

        </ul>

        <div class="inner clearfix">
            <p style="font-size: 16px">
                <u><b><em>Feature generation</em></b></u>:
                <br>We attempted several versions of feature generation and learned that including all feature
                types does not make the model better. Here, model 0 was our original model, where we included all
                Feature
                Types, including Euclidean distance, x distance, y distance, and the angle. However, the accuracy is the
                lowest among all models we built.
            </p>
        </div>
        <ul class="row grid cs-style-2">

            <img src="pics/how_ru_feeling/7.png" alt="how are you feeling feature generation">

        </ul>
        <div class="inner clearfix">
            <p style="font-size: 16px">
                <u><b><em>What we learned</em></b></u>:
                <br>XGBoost classifier model is the best.
                The most important feature came from the top and bottom lip with the Y-distance. This means that the
                model heavily relies on how far apart the top lip is from the bottom.

            </p>
        </div>
        <ul class="row grid cs-style-2">

            <img src="pics/how_ru_feeling/8.png" alt="how are you feeling learning">

        </ul>
        <div class="inner clearfix">
            <p style="font-size: 16px">
                <u><b><em>Demo</em></b></u>: <br>Our model successfully recognizes facial expressions of teammates.
            </p>
        </div>
        <ul class="row grid cs-style-2">

            <img src="pics/how_ru_feeling/9.png" alt="how are you feeling demo">

        </ul>

        <div class="inner clearfix">
            <p style="font-size: 16px">
                <u><b><em>Next steps</em></b></u>:</p>

            <ul style="font-size: 16px;">
                <li style="list-style: inside circle none;  text-align: left; margin: 0 0 0 2%;">Expand our dataset and
                    explore more.
                </li>
                <br>
                <li style="list-style: inside circle none;  text-align: left; margin: 0 0 0 2%;">Analyze the percentages
                    of each emotion instead of focusing on the most significant one. Most likely,
                    our facial expressions can show a combination of several emotions, such as happy and surprised,
                    fearful but angry. So we believe it could be better to analyze the percentage of each emotion to get a more
                    accurate result.
                </li>
                <br>
                <li style="list-style: inside circle none;  text-align: left; margin: 0 0 0 2%;">Extend our analysis to
                    include voice and body language. Many people try to control their emotions. If
                    we can combine facial expression, voice, and body language, we can analyze emotional
                    status more accurately.
                </li>
                <br>
            </ul>


        </div>
        <ul class="row grid cs-style-2">

            <img src="pics/how_ru_feeling/11.png" alt="how are you feeling next steps">

        </ul>

        <ul class="row grid cs-style-2">

            <img src="pics/how_ru_feeling/12.png" alt="how are you feeling conclusion">

        </ul>
        <br>
        <br>
        <!--GO BACK-->
        <div class="col-md-6" style="float: right">
            <a href="analyticalindex.html"> <input type="submit" class="form-control" value="Go Back"></a>
            &nbsp;&nbsp;&nbsp;&nbsp;<br>
        </div>
    </ul>
</div>
<!-- / Site Main -->


<!-- / JS Files  -->

<!-- jQuery -->
<script src="js/jQuery/jquery-2.1.1.js"></script>

<!-- Theme Functions -->
<script src="js/functions.js"></script>


</body>
</html>

